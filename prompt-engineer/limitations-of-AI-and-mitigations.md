# Limitations

- Cognitive limitations : they don't think like hums, they don't have common sense, they don't understand the world like humans do.
- Output quality and transparency : answers are based on their training and the questions you ask.
- Technical limitations : they can tricked or attacked.
- Privacy, Security and Regulatory limitations : they may store data and raise privacy concerns.


## Cognitive limitations

Models aim to generate the **next token to complete your prompt**, rather than solving the task itself; this is why they are highly sensitive to the prompt you provide.

- LLM don't know if they have produced good or bad output.
- LLM don't have an "inner monologue stream in the head" as humans do.
- They may "hallucinate"
- They may be biased 

## Output quality and transparency

- Dependency on prompt quality 
- Lack of training data and decision logic transparency : we don't understand how they make decisions.

## Technical limitations

- Prompt injection : Users can manipulate the input prompts to generate unwanted outputs or misinformation.
- Jailbreak attacks: refer to attempts by users to exploit the models beyond its intended use to violate ethical guidelines or laws.
- Data poisoning attacks : the training data has biased or harmful information, the generated outputs may also be biased or harmful
- Emerging vulnerabilities.